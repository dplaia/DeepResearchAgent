{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "from os.path import join, exists\n",
    "from os import listdir, makedirs\n",
    "from datetime import datetime\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "from crawl4ai import *\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from dataclasses import dataclass\n",
    "# Add this line to allow nested event loops\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flash_thinking_model = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "flash2_model = \"gemini-2.0-flash-exp\"\n",
    "flash1_model = \"gemini-1.5-flash\"\n",
    "model = GeminiModel(flash2_model)\n",
    "\n",
    "# @dataclass\n",
    "# class MainDependencies(BaseModel):\n",
    "#     document: str\n",
    "#     response: str\n",
    "\n",
    "class ModelRating(BaseModel):\n",
    "    rating: int = Field(description=\"The rating of the model (0 to 10).\", ge=0, le=10)\n",
    "    model_name: str = Field(description=\"The name of the model (if accessable).\")\n",
    "    evaluation_result: str = Field(description=\"Your assessment for this model. How good is the model? Describe it in detail.\")\n",
    "    \n",
    "class Response(BaseModel):\n",
    "    model_rating: list[ModelRating] = Field(description=\"A list of model ratings.\")\n",
    "\n",
    "system_prompt=\"\"\"You goal is to test two reasoning models (available as tools). \n",
    "Come up with a chellenging task that is relatively easy to verify to you but difficult to solve for other models if you provide only the task.\n",
    "You can try different tests, if you're not sure how good the models are. \n",
    "Provide a system instruction to the model that seems optimial for reasoning models. \n",
    "Avoid chain-of-though instructions. \n",
    "The models tend to perform better if they have more time to think.\n",
    "Come up with a system prompt that makes them think longer.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model,\n",
    "    result_type=Response,\n",
    "    system_prompt=system_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent.tool\n",
    "def run_deepseek_r1_agent(query, system_instruction=\"You are a helpful assistent\") -> str:\n",
    "    \"\"\"Uses the DeepSeek API to retrieve information based on a string query.\n",
    "    This model is a reasoner model and uses thinking tokens to generate better results.\n",
    "    Reasoning models tend to be better accross the board but especially in math, reasoning and coding.\n",
    "    This model is very powerful, open-source and cheap to use (2$ per 1M output tokens).\n",
    "\n",
    "    Args:\n",
    "        query (str): The LLM query string.\n",
    "        system_instruction (str, optional): The system instruction to use for the query. Defaults to \"You are a helpful assistent\". Adjust it, if it necessary.\n",
    "\n",
    "    Returns:\n",
    "        str: The output string of the DeepSeek R1 model. The returned string is the final answer of the AI model.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"OPENROUTER_API_KEY not found in environment variables.\")\n",
    "        return \"OPENROUTER_API_KEY not found in environment variables.\"\n",
    "    \n",
    "    client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key,\n",
    "    )\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-r1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_instruction\n",
    "        },        \n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    return completion.choices[0].message.content      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent.tool\n",
    "def run_genai_agent(query, system_instruction=\"You are a helpful assistent\") -> str:\n",
    "    \"\"\"Uses the Gemini API to use the Gemini-2.0 Flash Thinking model.\n",
    "    This model is a reasoner model and uses thinking tokens to generate better results.\n",
    "    Reasoning models tend to be better accross the board but especially in math, reasoning and coding.\n",
    "    This model is very powerful and free (1500 Req./day), has a context window of 1M tokens and can generate up to 65k tokens in one go.\n",
    "\n",
    "    Args:\n",
    "        query (str): The LLM query string.\n",
    "        system_instruction (str, optional): The system instruction to use for the query. Defaults to \"You are a helpful assistent\". Adjust it, if it necessary.\n",
    "\n",
    "    Returns:\n",
    "        str: The output string of the Gemini-2.0 Flash Thinking model. The returned string is the final answer of the AI model.\n",
    "    \"\"\"\n",
    "    # Only run this block for Gemini Developer API\n",
    "    client = genai.Client()    \n",
    "    flash_thinking_model = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "    response = client.models.generate_content(\n",
    "        model=flash_thinking_model,\n",
    "        contents=query,\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_instruction,\n",
    "            temperature=0.3,\n",
    "        ),\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent \"HTTP/1.1 400 Bad Request\"\n"
     ]
    },
    {
     "ename": "UnexpectedModelBehavior",
     "evalue": "Unexpected response from gemini 400, body:\n{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"* GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[system_instruction].type: must be specified when not using one_of\\n* GenerateContentRequest.tools[0].function_declarations[1].parameters.properties[system_instruction].type: must be specified when not using one_of\\n\",\n    \"status\": \"INVALID_ARGUMENT\"\n  }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedModelBehavior\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest the two models on chellenging tasks and give a rating.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/asyncio/futures.py:199\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mrun_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_agent\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest the two models on chellenging tasks and give a rating.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic_ai/agent.py:300\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, user_prompt, message_history, model, deps, model_settings, usage_limits, usage, result_type, infer_name)\u001b[0m\n\u001b[1;32m    297\u001b[0m     agent_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_model(run_context, result_schema)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _logfire\u001b[38;5;241m.\u001b[39mspan(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel request\u001b[39m\u001b[38;5;124m'\u001b[39m, run_step\u001b[38;5;241m=\u001b[39mrun_context\u001b[38;5;241m.\u001b[39mrun_step) \u001b[38;5;28;01mas\u001b[39;00m model_req_span:\n\u001b[0;32m--> 300\u001b[0m     model_response, request_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent_model\u001b[38;5;241m.\u001b[39mrequest(messages, model_settings)\n\u001b[1;32m    301\u001b[0m     model_req_span\u001b[38;5;241m.\u001b[39mset_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m, model_response)\n\u001b[1;32m    302\u001b[0m     model_req_span\u001b[38;5;241m.\u001b[39mset_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m'\u001b[39m, request_usage)\n",
      "File \u001b[0;32m~/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic_ai/models/gemini.py:174\u001b[0m, in \u001b[0;36mGeminiAgentModel.request\u001b[0;34m(self, messages, model_settings)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m, messages: \u001b[38;5;28mlist\u001b[39m[ModelMessage], model_settings: ModelSettings \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    173\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ModelResponse, usage\u001b[38;5;241m.\u001b[39mUsage]:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(messages, \u001b[38;5;28;01mFalse\u001b[39;00m, model_settings) \u001b[38;5;28;01mas\u001b[39;00m http_response:\n\u001b[1;32m    175\u001b[0m         response \u001b[38;5;241m=\u001b[39m _gemini_response_ta\u001b[38;5;241m.\u001b[39mvalidate_json(\u001b[38;5;28;01mawait\u001b[39;00m http_response\u001b[38;5;241m.\u001b[39maread())\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(response), _metadata_as_usage(response)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py:214\u001b[0m, in \u001b[0;36m_AsyncGeneratorContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic_ai/models/gemini.py:229\u001b[0m, in \u001b[0;36mGeminiAgentModel._make_request\u001b[0;34m(self, messages, streamed, model_settings)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m r\u001b[38;5;241m.\u001b[39maread()\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedModelBehavior(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected response from gemini \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, r\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m r\n",
      "\u001b[0;31mUnexpectedModelBehavior\u001b[0m: Unexpected response from gemini 400, body:\n{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"* GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[system_instruction].type: must be specified when not using one_of\\n* GenerateContentRequest.tools[0].function_declarations[1].parameters.properties[system_instruction].type: must be specified when not using one_of\\n\",\n    \"status\": \"INVALID_ARGUMENT\"\n  }\n}"
     ]
    }
   ],
   "source": [
    "async def run_agent():\n",
    "    result = await agent.run('Test the two models on chellenging tasks and give a rating.')\n",
    "    return result\n",
    " \n",
    "result = asyncio.run(run_agent())\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
