{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example DeepResearchAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os.path import join, exists\n",
    "from os import listdir, makedirs\n",
    "from datetime import datetime\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "from crawl4ai import *\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from dataclasses import dataclass\n",
    "# Add this line to allow nested event loops\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity Search API Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_perplexity_search_results(query):\n",
    "    api_key = os.environ.get(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"PERPLEXITY_API_KEY not found in environment variables.\")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an artificial intelligence assistant and you need to \"\n",
    "                \"engage in a helpful, detailed, polite conversation with a user.\"\n",
    "            ),\n",
    "        },\n",
    "        {   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                query\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    client = OpenAI(api_key=api_key, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "    # chat completion without streaming\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"sonar-pro\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message.content + \"\\n\\n\"\n",
    "    citations = response.citations\n",
    "\n",
    "    for k, citation in enumerate(citations):\n",
    "        message += f\"[{k+1}] {citation}\\n\"\n",
    "        #print(f\"[{k+1}] {citation}\")\n",
    "\n",
    "    return message, citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message, citations = get_perplexity_search_results(\"How many user queries can be done with the H100 und a 13B parameter LLM model?\")\n",
    "print(message)\n",
    "print(citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Search API Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API key is stored in the environment variable `SERPER_API_KEY`.  \n",
    "An account can be created [here](https://serper.dev/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_search_results(query, num_results=10):\n",
    "    api_key = os.environ.get(\"SERPER_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"SERPER_API_KEY not found in environment variables.\")\n",
    "        return\n",
    "\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "    \"q\": query,\n",
    "    \"num\": num_results\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Test-time compute and test-time training for Large Language Models.\"\n",
    "response = get_google_search_results(topic)\n",
    "# Convert to JSON\n",
    "json_response = response.json()\n",
    "print(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_website_async(url_webpage):\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=url_webpage,\n",
    "        )\n",
    "        return result.markdown\n",
    "\n",
    "def crawl_website(url_webpage):\n",
    "    return asyncio.run(crawl_website_async(url_webpage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://arxiv.org/html/2501.12895... | Status: True | Time: 1.77s\n",
      "[SCRAPE].. ◆ Processed https://arxiv.org/html/2501.12895... | Time: 300ms\n",
      "[COMPLETE] ● https://arxiv.org/html/2501.12895... | Status: True | Total: 2.07s\n"
     ]
    }
   ],
   "source": [
    "res = crawl_website(\"https://arxiv.org/html/2501.12895\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_folder = \"test-time-compute\"\n",
    "# Create folder if not exists\n",
    "if not exists(query_folder):\n",
    "    makedirs(query_folder)\n",
    "\n",
    "document_data = {}\n",
    "\n",
    "for result in json_response['organic']:\n",
    "    title = result['title']\n",
    "    markdown = crawl_website(result['link'])\n",
    "    filename = result['title'] + \".md\"\n",
    "\n",
    "    document_data[title] = {\n",
    "        'topic': topic,\n",
    "        'link': result['link'],\n",
    "        'snippet': result['snippet'],\n",
    "        'date': result['date'],\n",
    "        'position': result['position'],\n",
    "        'markdown': markdown,\n",
    "        'filename': filename\n",
    "    }\n",
    "\n",
    "    with open(join(query_folder, filename), \"w\") as f:\n",
    "        f.write(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent('openai:gpt-4o')\n",
    "\n",
    "result_sync = agent.run_sync('What is the capital of Italy?')\n",
    "print(result_sync.data)\n",
    "#> Rome\n",
    "\n",
    "async def run_agent_async():\n",
    "    result = await agent.run('What is the capital of France?')\n",
    "    print(result.data)\n",
    "    #> Paris\n",
    "\n",
    "    async with agent.run_stream('What is the capital of the UK?') as response:\n",
    "        print(await response.get_data())\n",
    "        #> London\n",
    "\n",
    "def run_agent():\n",
    "    asyncio.run(run_agent_async())\n",
    "\n",
    "run_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crate an Agent that rates the quality of generated content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this block for Gemini Developer API\n",
    "client = genai.Client()\n",
    "\n",
    "flash_thinking_model = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "flash2_model = \"gemini-2.0-flash-exp\"\n",
    "flash1_model = \"gemini-1.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_of_content=['1. Introduction to Test-Time Compute', '    1.1. The Need for Test-Time Compute', '    1.2. How Test-Time Compute Differs from Pre-training', '2. Core Concepts and Mechanisms', '    2.1. Inference-Time Optimization', '    2.2. Adaptive Resource Allocation', '    2.3. Iterative Refinement and Self-Verification', '    2.4. Reward Modeling and Verifiers', '    2.5. Search Methods and Exploration Strategies', '3. Test-Time Compute Techniques', '    3.1. Best-of-N Sampling', '    3.2. Iterative Refinement', '    3.3. Tree of Thoughts and Search Algorithms', '    3.4. Self-Critique and Revision', '    3.5. Active Fine-Tuning at Test-Time', '4. Compute-Optimal Scaling Strategies', '    4.1. Adaptive Compute Allocation Based on Task Difficulty', '    4.2. Dynamic Resource Management', '    4.3. Trading Off Pre-training and Test-Time Compute', '5. Impact on LLM Performance', '    5.1. Enhanced Reasoning Abilities', '    5.2. Improved Accuracy on Complex Tasks', '    5.3. Mitigation of Hallucinations', '6. Practical Implications and Future Directions', '    6.1. Hardware Considerations and Cost Efficiency', '    6.2. Potential for Self-Improving AI', '    6.3. New Research Avenues', '7. Conclusion', '8. References'] additional_notes='The search results indicate that test-time compute is a very promising research direction, with the potential to significantly improve the performance of LLMs, especially on complex reasoning tasks. It involves allocating additional computational resources during inference to refine model outputs, which can lead to better results than simply scaling up model size or training data. The key is adapting the compute based on the difficulty of the task.' text_summary=\"Test-time compute is a burgeoning field in AI, focusing on enhancing Large Language Model (LLM) performance by allocating additional computational resources during the inference phase. Unlike traditional pre-training methods, which involve increasing model size or training data, test-time compute enables models to dynamically adapt their processing based on the complexity of the task at hand. Core mechanisms include adaptive distribution updates, compute-optimal scaling, reward modeling, self-verification, and search methods. Key techniques include best-of-N sampling, iterative refinement, tree-of-thoughts, and self-critique, all aimed at iteratively improving a model's response. The field also seeks to balance pre-training and test-time compute, with the potential to use smaller models with enhanced test-time compute to match the performance of larger models. This offers a pathway for more efficient and capable AI systems, which adjust dynamically to the problems they are addressing, enabling future AI to better reflect human-like reasoning and problem-solving.\"\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from datetime import date\n",
    "model = GeminiModel(model_name)\n",
    "\n",
    "@dataclass\n",
    "class ResearchDeps:\n",
    "    research_topic: str = Field(description=\"The research topic of the document.\")\n",
    "    document_type: str = Field(description=\"The type of document for the table of content (paper/report/general document/webpage).\")\n",
    "    document_number_of_pages: int = Field(description=\"A rough estimate of how many pages the report will have. The table of content needs to reflect that.\")\n",
    "\n",
    "class TableOfContentResult(BaseModel):\n",
    "    table_of_content: list[str] = Field(description=\"The generated table of content for the scientific report/document.\")\n",
    "    additional_notes: str = Field(description=\"If you want to add commentary based on things you've observed during the processing of the data you can add it here.\")\n",
    "    text_summary: str = Field(description=\"A one page summary of the given research topic based on the search results.\")\n",
    "\n",
    "table_of_content_agent = Agent(\n",
    "    flash2_model,\n",
    "    deps_type=ResearchDeps,  \n",
    "    result_type=TableOfContentResult,\n",
    "    system_prompt=\"\"\"Your goal is to create the table of content for a scientific report based on given topic and given input text. \n",
    "    You don't need to generate the report (except the one page summary).\n",
    "    Use the following tools to collect information about the topic:\n",
    "    - google search tool \n",
    "    - perplexity search tool\n",
    "    \n",
    "    Use both tools to get an overview about the topic, then create the table of content for the report/paper/document.\n",
    "    The table of content needs to contain the most interessting and important parts of the topic based on the desired page count of the report (more details for more report pages).\n",
    "    \"\"\",  \n",
    ")\n",
    "\n",
    "@table_of_content_agent.system_prompt  \n",
    "async def get_system_prompt(ctx: RunContext[ResearchDeps]) -> str:  \n",
    "    return f'{ctx.deps.research_topic}'\n",
    "\n",
    "@table_of_content_agent.tool_plain  \n",
    "def perplexity_search(search_query: str) -> dict:\n",
    "    \"\"\"Uses the Serper API to retrieve google results based on a string query.\n",
    "    Certain search results could be faulty or irrelevant, please ignore these results.\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The Perplexity query string. Perplexity uses an LLM to do the processing of webpages. Use a query text that is most suitable for this.\n",
    "    \n",
    "    Returns:\n",
    "        search_result: A dictionary with the following fields:\n",
    "            - 'test_response' (str): The text response from the Perplexity LLM with citations in the form [1], [2], etc.\n",
    "            - 'citations' (list[str]): A list of citations used in the test_response\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    test_response, citations = get_perplexity_search_results(search_query)\n",
    "\n",
    "    search_result = {\n",
    "        'test_response': test_response,\n",
    "        'citations': citations\n",
    "    }\n",
    "    return search_result\n",
    "\n",
    "@table_of_content_agent.tool_plain  \n",
    "def google_search(search_query: str, topic_folder_name: str) -> dict:\n",
    "    \"\"\"Uses the Serper API to retrieve google results based on a string query.\n",
    "    Certain search results could be faulty or irrelevant, please ignore these results.\n",
    "\n",
    "    Args:\n",
    "        search_query:str The google query string. It needs to be suited for the given research topic.\n",
    "        topic_folder_name:str A suitable name for a folder (all search results are saved in this folder). It needs to be a valid folder name.\n",
    "    \n",
    "    Returns:\n",
    "        document_data: A dictionary with the following fields:\n",
    "            - 'topic': The research topic (=search_query)\n",
    "            - 'link': The webpage link\n",
    "            - 'snippet': A short snippet of the webpage\n",
    "            - 'date': The date of the webpage\n",
    "            - 'position': Element position\n",
    "            - 'markdown': The markdown text (webpage content)\n",
    "            - 'filename': filename (saved in folder with name=topic_folder_name)\n",
    "    \"\"\"\n",
    "    num_results = 10\n",
    "    api_key = os.environ.get(\"SERPER_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"SERPER_API_KEY not found in environment variables.\")\n",
    "        return\n",
    "\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "    \"q\": search_query,\n",
    "    \"num\": num_results\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    json_response = response.json()\n",
    "\n",
    "    # Create folder if not exists\n",
    "    if not exists(topic_folder_name):\n",
    "        makedirs(topic_folder_name)\n",
    "\n",
    "    document_data = {}\n",
    "\n",
    "    for result in json_response['organic']:\n",
    "        title = result['title']\n",
    "        markdown = crawl_website(result['link'])\n",
    "        filename = result['title'] + \".md\"\n",
    "\n",
    "        document_data[title] = {\n",
    "            'topic': search_query,\n",
    "            'link': result['link'],\n",
    "            'snippet': result['snippet'],\n",
    "            'date': result['date'],\n",
    "            'position': result['position'],\n",
    "            'markdown': markdown,\n",
    "            'filename': filename\n",
    "        }\n",
    "\n",
    "        with open(join(topic_folder_name, filename), \"w\") as f:\n",
    "            f.write(markdown)\n",
    "\n",
    "    return document_data\n",
    "\n",
    "result = table_of_content_agent.run_sync('Write a table of content for a scientific report.', deps=ResearchDeps(research_topic=\"Test-time compute and training for LLMs\", document_type=\"Scientific Report\", document_number_of_pages=\"20\"))\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summary = result.data.text_summary\n",
    "additional_notes = result.data.additional_notes\n",
    "table_of_content = \"\" \n",
    "for item in result.data.table_of_content:\n",
    "    table_of_content += f\"- {item}\\n\"\n",
    "\n",
    "document_text = f\"\"\"Text Summary:\n",
    "{text_summary}\n",
    "\n",
    "Additional Notes:\n",
    "{additional_notes}\n",
    "\n",
    "Table of Content:\n",
    "{table_of_content}\n",
    "\"\"\"\n",
    "\n",
    "# Save document to file\n",
    "with open(\"document.md\", \"w\") as f:\n",
    "    f.write(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentQuality(BaseModel):\n",
    "    filename: str = Field(description=\"The name of the file\")   \n",
    "    document_length: int = Field(description=\"The length of the document (0 to 10). Is the document short or long.\", ge=0, le=10)\n",
    "    relevance: int = Field(description=\"How relevant is the document with the main topic (0 to 10).\", ge=0, le=10)\n",
    "    document_quality: int = Field(description=\"Guess the quality of the document (0 to 10).\", ge=0, le=10)\n",
    "    document_age: int = Field(description=\"The age of the document relative to the current data (0 to 10).\", ge=0, le=10)\n",
    "    additional_observations: str = Field(description=\"If you noticed something strange about the document. Write it in form of an instruction for another LLM agents.\")\n",
    "\n",
    "def rate_document(document):\n",
    "\n",
    "    system_instruction = f\"\"\"\n",
    "    You are an professional scientific journalist. \n",
    "\n",
    "    You will receive research related documents (markdown format). \n",
    "    Your goal is to estimate the relevance and quality of this document (based on a given topic).\n",
    "    The document will later be used for writing a reasearch report/document.\n",
    "    If the quality of the text isn't good, this will lead to an overall bad outcome of the report. \n",
    "\n",
    "    Topic: {document['topic']}    \n",
    "    Current Date: {datetime.now().date()}\n",
    "    Document Date: {document['date']}\n",
    "    Link: {document['link']}\n",
    "    \"\"\"\n",
    "\n",
    "    markdown_content = markdown\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=markdown_content,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=DocumentQuality,\n",
    "            system_instruction=system_instruction,\n",
    "            temperature=0.3,\n",
    "        ),\n",
    "    )\n",
    "    document['response'] = response\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Files (Quality Assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder if not exists\n",
    "if exists(query_folder):\n",
    "    # Get all files in folder\n",
    "    files = listdir(query_folder)\n",
    "\n",
    "for title, document in document_data.items():\n",
    "    print(f\"File: {document.filename}\")\n",
    "    document = rate_document(document)\n",
    "    print(f\"Reponse Text: {response.text}\")\n",
    "    document_data[title] = document\n",
    "    time.sleep(5) # sleep for 5 seconds (rate limit is 10 RPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"You are an AI assistant designed to produce output that is visually appealing and easily readable in a terminal. When formatting your responses, utilize the syntax of the Python `rich` library. This involves using square brackets to enclose formatting tags.\n",
    "        Here are some examples of how to apply formatting:\n",
    "\n",
    "        * **Emphasis:** Instead of \"This is important\", output \"[bold]This is important[/]\".\n",
    "        * **Headers/Titles:** Instead of \"Section Title:\", output \"[bold blue]Section Title:[/]\".\n",
    "        * **Warnings:** Instead of \"Warning!\", output \"[bold red]Warning![/]\".\n",
    "        * **Success Messages:** Instead of \"Operation successful.\", output \"[green]Operation successful.[/]\".\n",
    "        * **Lists:** You can use colors for list items like \"[cyan]*[/] Item 1\".\n",
    "\n",
    "        Always use the `rich` library's syntax for formatting terminal output to enhance readability.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_name_thinking,\n",
    "    contents=\"Show me the proof for the euler identity?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        temperature=0.3,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.upload(path=\"a11.text\")\n",
    "response = client.models.generate_content(\n",
    "    model=model_name, contents=[\"Summarize this file\", file]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dplaia/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `str` with value `'STRING'` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Boston is sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"capital\": \"Washington, D.C.\",\n",
      "\"continent\": \"North America\",\n",
      "\"gdp\": 25460000000000,\n",
      "\"name\": \"United States\",\n",
      "\"official_language\": \"English\",\n",
      "\"population\": 331002651,\n",
      "\"total_area_sq_mi\": 3796742\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"Give me information for the United States.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
