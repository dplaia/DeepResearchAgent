{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example DeepResearchAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os.path import join, exists\n",
    "from os import listdir, makedirs\n",
    "from datetime import datetime\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from crawl4ai import *\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "# Add this line to allow nested event loops\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity Search API Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_perplexity_search_results(query):\n",
    "    api_key = os.environ.get(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"PERPLEXITY_API_KEY not found in environment variables.\")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an artificial intelligence assistant and you need to \"\n",
    "                \"engage in a helpful, detailed, polite conversation with a user.\"\n",
    "            ),\n",
    "        },\n",
    "        {   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                query\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    client = OpenAI(api_key=api_key, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "    # chat completion without streaming\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"sonar-pro\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message.content + \"\\n\\n\"\n",
    "    citations = response.citations\n",
    "\n",
    "    for k, citation in enumerate(citations):\n",
    "        message += f\"[{k+1}] {citation}\\n\"\n",
    "        #print(f\"[{k+1}] {citation}\")\n",
    "\n",
    "    return message, citations\n",
    "\n",
    "\n",
    "message, citations = get_perplexity_search_results(\"How many user queries can be done with the H100 und a 13B parameter LLM model?\")\n",
    "print(message)\n",
    "print(citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Search API Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API key is stored in the environment variable `SERPER_API_KEY`.  \n",
    "An account can be created [here](https://serper.dev/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_search_results(query, num_results=10):\n",
    "    api_key = os.environ.get(\"SERPER_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"SERPER_API_KEY not found in environment variables.\")\n",
    "        return\n",
    "\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "    \"q\": query,\n",
    "    \"num\": num_results\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    return response\n",
    "    \n",
    "topic = \"Test-time compute and test-time training for Large Language Models.\"\n",
    "response = get_google_search_results(topic)\n",
    "# Convert to JSON\n",
    "json_response = response.json()\n",
    "print(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_website_async(url_webpage):\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=url_webpage,\n",
    "        )\n",
    "        return result.markdown\n",
    "\n",
    "def crawl_website(url_webpage):\n",
    "    return asyncio.run(crawl_website_async(url_webpage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://arxiv.org/html/2501.12895... | Status: True | Time: 1.77s\n",
      "[SCRAPE].. ◆ Processed https://arxiv.org/html/2501.12895... | Time: 300ms\n",
      "[COMPLETE] ● https://arxiv.org/html/2501.12895... | Status: True | Total: 2.07s\n"
     ]
    }
   ],
   "source": [
    "res = crawl_website(\"https://arxiv.org/html/2501.12895\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_folder = \"test-time-compute\"\n",
    "# Create folder if not exists\n",
    "if not exists(query_folder):\n",
    "    makedirs(query_folder)\n",
    "\n",
    "document_data = {}\n",
    "\n",
    "for result in json_response['organic']:\n",
    "    title = result['title']\n",
    "    markdown = crawl_website(result['link'])\n",
    "    filename = result['title'] + \".md\"\n",
    "\n",
    "    document_data[title] = {\n",
    "        'topic': topic,\n",
    "        'link': result['link'],\n",
    "        'snippet': result['snippet'],\n",
    "        'date': result['date'],\n",
    "        'position': result['position'],\n",
    "        'markdown': markdown,\n",
    "        'filename': filename\n",
    "    }\n",
    "\n",
    "    with open(join(query_folder, filename), \"w\") as f:\n",
    "        f.write(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this block for Gemini Developer API\n",
    "client = genai.Client()\n",
    "\n",
    "flash_thinking_model = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "flash2_model = \"gemini-2.0-flash-exp\"\n",
    "flash1_model = \"gemini-1.5-flash\"\n",
    "\n",
    "model = GeminiModel(flash1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentQuality(BaseModel):\n",
    "    filename: str = Field(description=\"The name of the file\")   \n",
    "    document_length: int = Field(description=\"The length of the document (0 to 10). Is the document short or long.\", ge=0, le=10)\n",
    "    relevance: int = Field(description=\"How relevant is the document with the main topic (0 to 10).\", ge=0, le=10)\n",
    "    document_quality: int = Field(description=\"Guess the quality of the document (0 to 10).\", ge=0, le=10)\n",
    "    document_age: int = Field(description=\"The age of the document relative to the current data (0 to 10).\", ge=0, le=10)\n",
    "    additional_observations: str = Field(description=\"If you noticed something strange about the document. Write it in form of an instruction for another LLM agents.\")\n",
    "\n",
    "def rate_document(document):\n",
    "\n",
    "    system_instruction = f\"\"\"\n",
    "    You are an professional scientific journalist. \n",
    "\n",
    "    You will receive research related documents (markdown format). \n",
    "    Your goal is to estimate the relevance and quality of this document (based on a given topic).\n",
    "    The document will later be used for writing a reasearch report/document.\n",
    "    If the quality of the text isn't good, this will lead to an overall bad outcome of the report. \n",
    "\n",
    "    Topic: {document['topic']}    \n",
    "    Current Date: {datetime.now().date()}\n",
    "    Document Date: {document['date']}\n",
    "    Link: {document['link']}\n",
    "    \"\"\"\n",
    "\n",
    "    markdown_content = markdown\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=markdown_content,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=DocumentQuality,\n",
    "            system_instruction=system_instruction,\n",
    "            temperature=0.3,\n",
    "        ),\n",
    "    )\n",
    "    document['response'] = response\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Files (Quality Assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder if not exists\n",
    "if exists(query_folder):\n",
    "    # Get all files in folder\n",
    "    files = listdir(query_folder)\n",
    "\n",
    "for title, document in document_data.items():\n",
    "    print(f\"File: {document.filename}\")\n",
    "    document = rate_document(document)\n",
    "    print(f\"Reponse Text: {response.text}\")\n",
    "    document_data[title] = document\n",
    "    time.sleep(5) # sleep for 5 seconds (rate limit is 10 RPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"You are an AI assistant designed to produce output that is visually appealing and easily readable in a terminal. When formatting your responses, utilize the syntax of the Python `rich` library. This involves using square brackets to enclose formatting tags.\n",
    "        Here are some examples of how to apply formatting:\n",
    "\n",
    "        * **Emphasis:** Instead of \"This is important\", output \"[bold]This is important[/]\".\n",
    "        * **Headers/Titles:** Instead of \"Section Title:\", output \"[bold blue]Section Title:[/]\".\n",
    "        * **Warnings:** Instead of \"Warning!\", output \"[bold red]Warning![/]\".\n",
    "        * **Success Messages:** Instead of \"Operation successful.\", output \"[green]Operation successful.[/]\".\n",
    "        * **Lists:** You can use colors for list items like \"[cyan]*[/] Item 1\".\n",
    "\n",
    "        Always use the `rich` library's syntax for formatting terminal output to enhance readability.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=flash_thinking_model,\n",
    "    contents=\"Show me the proof for the euler identity?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        temperature=0.3,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.upload(path=\"a11.text\")\n",
    "response = client.models.generate_content(\n",
    "    model=model_name, contents=[\"Summarize this file\", file]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dplaia/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `str` with value `'STRING'` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Boston is sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"capital\": \"Washington, D.C.\",\n",
      "\"continent\": \"North America\",\n",
      "\"gdp\": 25460000000000,\n",
      "\"name\": \"United States\",\n",
      "\"official_language\": \"English\",\n",
      "\"population\": 331002651,\n",
      "\"total_area_sq_mi\": 3796742\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"Give me information for the United States.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if URL is a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def is_pdf_url(url, timeout=5):\n",
    "    try:\n",
    "        # Try HEAD first to avoid downloading content\n",
    "        response = requests.head(url, allow_redirects=True, timeout=timeout)\n",
    "\n",
    "        # Fallback to GET if HEAD not allowed\n",
    "        if response.status_code == 405:\n",
    "            response = requests.get(url, stream=True, timeout=timeout)\n",
    "\n",
    "        content_type = response.headers.get('Content-Type', '').lower()\n",
    "        return 'application/pdf' in content_type\n",
    "\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "print(is_pdf_url(\"https://arxiv.org/pdf/2501.12895\"))  # True for PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PapersWithCode API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://paperswithcode.com/api/v1/search/\"\n",
    "params = {\n",
    "    \"page\": 1,\n",
    "    \"items_per_page\": 200,\n",
    "    \"q\": \"test-time compute\"  # Space will be auto-encoded to \"%20\"\n",
    "}\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"X-CSRFToken\": \"2ix1PR0FtUWIW5ePo08I3vhgHsvJ6fpqj0x1Ijjo4egxiofnUBzkX67bnHwbNd8G\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Send GET request\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status()  # Raise exception for HTTP errors (e.g., 4xx/5xx)\n",
    "    \n",
    "    # Parse JSON response\n",
    "    data = response.json()\n",
    "    print(\"API Response:\")\n",
    "    print(data)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Failed to parse JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(data)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'arxiv_id', 'nips_id', 'url_abs', 'url_pdf', 'title', 'abstract', 'authors', 'published', 'conference', 'conference_url_abs', 'conference_url_pdf', 'proceeding'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['results'][0]['paper'].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
