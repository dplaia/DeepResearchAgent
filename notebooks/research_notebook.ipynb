{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example DeepResearchAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os.path import join, exists\n",
    "from os import listdir, makedirs\n",
    "from datetime import datetime\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from crawl4ai import *\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "# Add this line to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from agent_tools import *\n",
    "from agent_utils import *\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl Webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_folder = \"test-time-compute\"\n",
    "# Create folder if not exists\n",
    "if not exists(query_folder):\n",
    "    makedirs(query_folder)\n",
    "\n",
    "document_data = {}\n",
    "\n",
    "for result in json_response['organic']:\n",
    "    title = result['title']\n",
    "    markdown = crawl_website(result['link'])\n",
    "    filename = result['title'] + \".md\"\n",
    "\n",
    "    document_data[title] = {\n",
    "        'topic': topic,\n",
    "        'link': result['link'],\n",
    "        'snippet': result['snippet'],\n",
    "        'date': result['date'],\n",
    "        'position': result['position'],\n",
    "        'markdown': markdown,\n",
    "        'filename': filename\n",
    "    }\n",
    "\n",
    "    with open(join(query_folder, filename), \"w\") as f:\n",
    "        f.write(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentQuality(BaseModel):\n",
    "    filename: str = Field(description=\"The name of the file\")   \n",
    "    document_length: int = Field(description=\"The length of the document (0 to 10). Is the document short or long.\", ge=0, le=10)\n",
    "    relevance: int = Field(description=\"How relevant is the document with the main topic (0 to 10).\", ge=0, le=10)\n",
    "    document_quality: int = Field(description=\"Guess the quality of the document (0 to 10).\", ge=0, le=10)\n",
    "    document_age: int = Field(description=\"The age of the document relative to the current data (0 to 10).\", ge=0, le=10)\n",
    "    additional_observations: str = Field(description=\"If you noticed something strange about the document. Write it in form of an instruction for another LLM agents.\")\n",
    "\n",
    "def rate_document(document):\n",
    "\n",
    "    system_instruction = f\"\"\"\n",
    "    You are an professional scientific journalist. \n",
    "\n",
    "    You will receive research related documents (markdown format). \n",
    "    Your goal is to estimate the relevance and quality of this document (based on a given topic).\n",
    "    The document will later be used for writing a reasearch report/document.\n",
    "    If the quality of the text isn't good, this will lead to an overall bad outcome of the report. \n",
    "\n",
    "    Topic: {document['topic']}    \n",
    "    Current Date: {datetime.now().date()}\n",
    "    Document Date: {document['date']}\n",
    "    Link: {document['link']}\n",
    "    \"\"\"\n",
    "\n",
    "    markdown_content = markdown\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=markdown_content,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=DocumentQuality,\n",
    "            system_instruction=system_instruction,\n",
    "            temperature=0.3,\n",
    "        ),\n",
    "    )\n",
    "    document['response'] = response\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Files (Quality Assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder if not exists\n",
    "if exists(query_folder):\n",
    "    # Get all files in folder\n",
    "    files = listdir(query_folder)\n",
    "\n",
    "for title, document in document_data.items():\n",
    "    print(f\"File: {document.filename}\")\n",
    "    document = rate_document(document)\n",
    "    print(f\"Reponse Text: {response.text}\")\n",
    "    document_data[title] = document\n",
    "    time.sleep(5) # sleep for 5 seconds (rate limit is 10 RPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"You are an AI assistant designed to produce output that is visually appealing and easily readable in a terminal. When formatting your responses, utilize the syntax of the Python `rich` library. This involves using square brackets to enclose formatting tags.\n",
    "        Here are some examples of how to apply formatting:\n",
    "\n",
    "        * **Emphasis:** Instead of \"This is important\", output \"[bold]This is important[/]\".\n",
    "        * **Headers/Titles:** Instead of \"Section Title:\", output \"[bold blue]Section Title:[/]\".\n",
    "        * **Warnings:** Instead of \"Warning!\", output \"[bold red]Warning![/]\".\n",
    "        * **Success Messages:** Instead of \"Operation successful.\", output \"[green]Operation successful.[/]\".\n",
    "        * **Lists:** You can use colors for list items like \"[cyan]*[/] Item 1\".\n",
    "\n",
    "        Always use the `rich` library's syntax for formatting terminal output to enhance readability.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=flash_thinking_model,\n",
    "    contents=\"Show me the proof for the euler identity?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        temperature=0.3,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.upload(path=\"a11.text\")\n",
    "response = client.models.generate_content(\n",
    "    model=model_name, contents=[\"Summarize this file\", file]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dplaia/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `str` with value `'STRING'` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Boston is sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WebSearchAgent import *\n",
    "response = await google_scholar_search(\"RAG Benchmark\", num_pages=3)\n",
    "paper = response[0]\n",
    "title = paper['title']\n",
    "link = paper['link']\n",
    "pdfUrl = paper['pdfUrl']\n",
    "print(f\"{title}\")\n",
    "print(f\"    ({link.replace(\"https://\",\"\")}) ({pdfUrl.replace(\"https://\",\"\")})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper With Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwc_title = await papers_with_code_search(title)['results'][0]['paper']['title']\n",
    "pwc_pdf = papers_with_code_search(title)['results'][0]['paper']['url_pdf']\n",
    "print(f\"{pwc_title}  ({pwc_pdf})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"OpenRouter Deepseek R1 for free\"\n",
    "response = await google_general_search(query)\n",
    "rprint(response)\n",
    "#console.print(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
