{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "from crawl4ai import *\n",
    "\n",
    "# Add this line to allow nested event loops\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_website(url_webpage):\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=url_webpage,\n",
    "        )\n",
    "        return result.markdown\n",
    "\n",
    "def run(url_webpage):\n",
    "    return asyncio.run(crawl_website(url_webpage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www.golem.de/... | Status: True | Time: 0.00s\n",
      "[COMPLETE] ● https://www.golem.de/... | Status: True | Total: 0.01s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[ ![Golem.de - IT-News für Profis](https://www.golem.de/staticrl/images/logo-g.png) ](https://www.golem.de/<https:/www.golem.de/>) [ ](https://www.golem.de/<https:/redirect.golem.de/nl.php?id=account_login_cmp>)\\n# Willkommen auf Golem.de!\\n## Cookies zustimmen\\nBesuchen Sie Golem.de wie gewohnt mit Werbung und Tracking, indem Sie der Nutzung aller Cookies zustimmen. Details zum Tracking finden Sie im Privacy Center. \\nUm der Nutzung von Golem.de mit Cookies zustimmen zu können, müssen Cookies in Ihrem Browser aktiviert sein. Weitere Informationen finden Sie [hier](https://www.golem.de/<https:/www.golem.de/sonstiges/techinfo.html>). \\nDie Zustimmung in einem iFrame ist nicht möglich. [Seite in eigenem Fenster öffnen](https://www.golem.de/<#>). \\nDer Zustimmungs-Dialog konnte nicht korrekt geladen werden, eine Zustimmung gilt nur vorläufig. Informationen zur Problem\\xadbehandlung finden Sie [hier](https://www.golem.de/<https:/www.golem.de/sonstiges/techinfo.html>). \\nDie Möglichkeit zum Widerruf finden Sie in unserer [Datenschutz\\xaderklärung](https://www.golem.de/<https:/www.golem.de/sonstiges/Datenschutz.html#Widerruf>) oder über den Link Cookies & Tracking am Ende jeder Seite. \\n## … oder Golem pur bestellen\\nMit Golem pur ab 3 Euro pro Monat können Sie Golem.de ohne Analyse- und Werbe\\xadcookies nutzen, es kommen nur für unser Angebot erforderliche Cookies zum Einsatz. \\n[Zu Golem pur](https://www.golem.de/<https:/redirect.golem.de/nl.php?id=account_cta_cmp>)\\nBereits Pur-Leser? [Hier anmelden](https://www.golem.de/<https:/account.golem.de/user/login?redirect=https%3A%2F%2Fwww.golem.de%2F>). Kein aktives Abo vorhanden.\\n**Für die Nutzung mit Werbung:** Wir erheben personenbezogene Daten und übermitteln diese auch an bis zu 160 Drittanbieter, die uns helfen, unsere Webseite und Angebote zu verbessern und zu finanzieren. Eine Verarbeitung der auf Ihrem Gerät gespeicherten Informationen - z. B. Cookies oder persönliche Identifikatoren wie IP-Adressen - sowie Ihres individuellen Nutzungsverhaltens erfolgt dabei zu den folgenden Zwecken: \\nInformationen auf einem Gerät speichern und/oder abrufen\\nFür die Ihnen angezeigten Verarbeitungszwecke können Cookies, Geräte-Kennungen oder andere Informationen auf Ihrem Gerät gespeichert oder abgerufen werden. \\nPersonalisierte Anzeigen und Inhalte, Anzeigen- und Inhaltsmessungen, Erkenntnisse über Zielgruppen und Produktentwicklungen\\nAnzeigen und Inhalte können basierend auf einem Profil personalisiert werden. Es können mehr Daten hinzugefügt werden, um Anzeigen und Inhalte besser zu personalisieren. Die Performance von Anzeigen und Inhalten kann gemessen werden. Erkenntnisse über Zielgruppen, die die Anzeigen und Inhalte betrachtet haben, können abgeleitet werden. Daten können verwendet werden, um Benutzerfreundlichkeit, Systeme und Software aufzubauen oder zu verbessern. \\nGenaue Standortdaten verwenden\\nEs können genaue Standortdaten verarbeitet werden, um sie für einen oder mehrere Verarbeitungszwecke zu nutzen. \\n[Impressum](https://www.golem.de/<https:/www.golem.de/sonstiges/impressum.html>) [Datenschutz](https://www.golem.de/<https:/www.golem.de/sonstiges/Datenschutz.html>) [Golem pur AGB](https://www.golem.de/<https:/redirect.golem.de/nl.php?id=account_agb_cmp>)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"https://www.golem.de/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this block for Gemini Developer API\n",
    "client = genai.Client()\n",
    "\n",
    "model_name_thinking = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "model_name = \"gemini-2.0-flash-exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_name_thinking, contents=\"Is it difficult to find large prime numbers? If yes, why?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"You are an AI assistant designed to produce output that is visually appealing and easily readable in a terminal. When formatting your responses, utilize the syntax of the Python `rich` library. This involves using square brackets to enclose formatting tags.\n",
    "        Here are some examples of how to apply formatting:\n",
    "\n",
    "        * **Emphasis:** Instead of \"This is important\", output \"[bold]This is important[/]\".\n",
    "        * **Headers/Titles:** Instead of \"Section Title:\", output \"[bold blue]Section Title:[/]\".\n",
    "        * **Warnings:** Instead of \"Warning!\", output \"[bold red]Warning![/]\".\n",
    "        * **Success Messages:** Instead of \"Operation successful.\", output \"[green]Operation successful.[/]\".\n",
    "        * **Lists:** You can use colors for list items like \"[cyan]*[/] Item 1\".\n",
    "\n",
    "        Always use the `rich` library's syntax for formatting terminal output to enhance readability.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_name_thinking,\n",
    "    contents=\"Show me the proof for the euler identity?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        temperature=0.3,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.upload(path=\"a11.text\")\n",
    "response = client.models.generate_content(\n",
    "    model=model_name, contents=[\"Summarize this file\", file]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_search_results(query, num_results=10):\n",
    "    api_key = os.environ.get(\"SERPER_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"SERPER_API_KEY not found in environment variables.\")\n",
    "        return\n",
    "\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    payload = json.dumps({\n",
    "    \"q\": query,\n",
    "    \"num\": num_results\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    return response\n",
    "\n",
    "response = get_google_search_results(\"LLM test-time compute and training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'searchParameters': {'q': 'LLM test-time compute and training', 'type': 'search', 'engine': 'google'}, 'organic': [{'title': 'Optimizing LLM Test-Time Compute Involves Solving a Meta-RL ...', 'link': 'https://blog.ml.cmu.edu/2025/01/08/optimizing-llm-test-time-compute-involves-solving-a-meta-rl-problem/', 'snippet': 'In this post, we will discuss one such approach: by altering the LLM training objective, we can reuse existing data along with more test-time ...', 'date': 'Jan 8, 2025', 'position': 1}, {'title': 'Test-Time Compute: The Next Frontier in AI Scaling - IKANGAI', 'link': 'https://www.ikangai.com/test-time-compute-the-next-frontier-in-ai-scaling/', 'snippet': 'Major AI labs are exploring test-time compute, where models receive extra processing time during execution to produce better results.', 'date': 'Nov 12, 2024', 'position': 2}, {'title': 'What is Test Time Compute? | CSA', 'link': 'https://cloudsecurityalliance.org/blog/2024/12/13/test-time-compute', 'snippet': 'Test-time compute often involves using search methods to explore possible solutions dynamically. Techniques like beam search or tree-based ...', 'date': 'Dec 13, 2024', 'position': 3}, {'title': 'Understanding Test-Time Compute: A New Mechanism Allowing AI ...', 'link': 'https://medium.com/@rendysatriadalimunthe/understanding-test-time-compute-a-new-mechanism-allowing-ai-to-think-harder-19e017abc540', 'snippet': 'The test-time compute is a concept designed to solve this limitation. This mechanism allows the model to use extra computing power while handling complex ...', 'date': 'Nov 21, 2024', 'position': 4}, {'title': 'Train Less, Think More: Advancing LLMs Through Test-Time Compute', 'link': 'https://medium.com/electronic-life/train-less-think-more-advancing-llms-through-test-time-compute-a46832e973e9', 'snippet': 'A new frontier of test-time compute scaling has arrived, allowing smaller models to match or beat bigger ones on complex tasks by selectively thinking longer.', 'date': 'Dec 21, 2024', 'position': 5}, {'title': 'Scaling LLM Test-Time Compute Optimally can be More Effective ...', 'link': 'https://arxiv.org/abs/2408.03314', 'snippet': 'Enabling LLMs to improve their outputs by using more test-time computation is a critical step towards building generally self-improving agents ...', 'date': 'Aug 6, 2024', 'position': 6}, {'title': 'Scaling LLM Test Time Compute', 'link': 'https://www.jonvet.com/blog/llm-test-time-compute', 'snippet': 'Test time compute refers to the amount of compute that is used to generate completions from a language model (LLM) at test or inference time.', 'date': 'Oct 20, 2024', 'position': 7}, {'title': 'Test Time Training Will Take LLM AI to the Next Level', 'link': 'https://www.nextbigfuture.com/2024/11/test-time-training-will-take-llm-ai-to-the-next-level.html', 'snippet': \"Test-time training involves temporarily updating the model's parameters during inference using a loss function derived from the input data. The ...\", 'date': 'Nov 15, 2024', 'position': 8}, {'title': 'Scaling LLM Test-Time Compute Optimally can be More Effective ...', 'link': 'https://arxiv.org/html/2408.03314v1', 'snippet': 'In this work, we analyze two primary mechanisms to scale test-time computation: (1) searching against dense, process-based verifier reward models; and (2) ...', 'date': 'Aug 6, 2024', 'position': 9}, {'title': 'Scaling test-time compute - a Hugging Face Space by ...', 'link': 'https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute', 'snippet': 'Test-time compute can be scaled optimally through strategies like iterative self-refinement or using a reward model to perform search over the space of ...', 'date': 'Dec 16, 2024', 'sitelinks': [{'title': 'Strategies for test-time...', 'link': 'https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute#strategies_for_test-time_compute_scaling'}, {'title': 'Experimental setup', 'link': 'https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute#experimental_setup'}, {'title': 'Beam search with process...', 'link': 'https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute#beam_search_with_process_reward_models'}], 'position': 10}], 'peopleAlsoAsk': [{'question': 'What is LLM test-time compute?', 'snippet': 'Major AI labs, including OpenAI, are shifting their focus away from building ever-larger language models (LLMs). Instead, they are exploring \"test-time compute\", where models receive extra processing time during execution to produce better results.\\nNov 12, 2024', 'title': 'Test-Time Compute: The Next Frontier in AI Scaling - IKANGAI', 'link': 'https://www.ikangai.com/test-time-compute-the-next-frontier-in-ai-scaling/'}, {'question': 'What does test-time compute mean?', 'snippet': 'Test-time compute often involves using search methods to explore possible solutions dynamically. Techniques like beam search or tree-based exploration (e.g., Monte Carlo Tree Search) allow the system to evaluate multiple paths or outputs, enabling it to find the most optimal solution within computational constraints.\\nDec 13, 2024', 'title': 'What is Test Time Compute? | CSA', 'link': 'https://cloudsecurityalliance.org/blog/2024/12/13/test-time-compute'}, {'question': 'What is test-time compute in AI?', 'snippet': 'Enter test-time compute: a strategy that allows a model to pause, run multiple solution paths, reflect, and refine its answer on the fly.', 'title': 'Test-Time Compute: why “Thinking” AI Models are shaping the future', 'link': 'https://www.silamir.com/insight/test-time-compute-why-thinking-ai-models-are-shaping-the-future/'}], 'credits': 1}\n"
     ]
    }
   ],
   "source": [
    "# Convert to JSON\n",
    "json_response = response.json()\n",
    "print(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Optimizing LLM Test-Time Compute Involves Solving a Meta-RL ...',\n",
       " 'link': 'https://blog.ml.cmu.edu/2025/01/08/optimizing-llm-test-time-compute-involves-solving-a-meta-rl-problem/',\n",
       " 'snippet': 'In this post, we will discuss one such approach: by altering the LLM training objective, we can reuse existing data along with more test-time ...',\n",
       " 'date': 'Jan 8, 2025',\n",
       " 'position': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['organic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dplaia/Projekte/DeepResearchAgent/.venv/lib/python3.13/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `str` with value `'STRING'` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Boston is sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"capital\": \"Washington, D.C.\",\n",
      "\"continent\": \"North America\",\n",
      "\"gdp\": 25460000000000,\n",
      "\"name\": \"United States\",\n",
      "\"official_language\": \"English\",\n",
      "\"population\": 331002651,\n",
      "\"total_area_sq_mi\": 3796742\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    contents=\"Give me information for the United States.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
