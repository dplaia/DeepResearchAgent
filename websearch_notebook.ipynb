{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os.path import join, exists\n",
    "from os import listdir, makedirs\n",
    "from datetime import datetime\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "from openai import AsyncOpenAI\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from crawl4ai import *\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "import asyncio\n",
    "import nest_asyncio \n",
    "# Add this line to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from WebSearchAgent import *\n",
    "from agent_tools import *\n",
    "from agent_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "response = perplexity_sonar_reasoning(query)\n",
    "\n",
    "console = Console()\n",
    "console.print(Markdown(response['text_response']))\n",
    "\n",
    "citation_text = \"References:\\n\"\n",
    "for (k, l) in enumerate(response['citations']):\n",
    "    citation_text += f\"[{k+1}] {l}\\n\"\n",
    "\n",
    "rprint(citation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    text_response: str = Field(description=\"The text response of the agent.\")\n",
    "    additional_notes: str = Field(description=\"Additional notes or observations (optional).\")\n",
    "    tools_used: list[str] = Field(description=\"List all tools that you have used (e.g. Google Search, Papers With Code, etc.)\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a web search agent. Choose the search and crawling tools that available to you.\n",
    "Write a report of the search results. Write it down as a form of a news article/blog post.\n",
    "\n",
    "Use the webcrawler for links that you find in the search results but only if it seems useful.\n",
    "\n",
    "Number of function calling are limited:\n",
    "\n",
    "For news you can use:\n",
    "- google_general_search (up to 3 calls)\n",
    "- google_news_search  (up to 3 calls)\n",
    "\n",
    "For scientific papers:\n",
    "- google_scholar_search (up to 3 calls)\n",
    "- papers_with_code_search  (up to 3 calls)\n",
    "\n",
    "Web crawling:\n",
    "- crawl_website_async (up to 3 calls in total).\n",
    "\n",
    "If possible add citations. e.g. [1].\n",
    "\n",
    "At the end of the document:\n",
    "[1] www.example.com\n",
    "[2] etc.\n",
    "\n",
    "The output/formatting should be MarkDown. \n",
    "\"\"\"\n",
    "tools_list = [google_general_search, google_scholar_search, papers_with_code_search, crawl_website_async, google_news_search] #perplexity_search,\n",
    "\n",
    "# Create agent with selected tools\n",
    "agent = Agent(\n",
    "    model,\n",
    "    result_type=Response,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tools_list\n",
    ")\n",
    "\n",
    "query = \"Find me papers about test-time compute and training.\"\n",
    "result = await agent.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "# Create a console instance\n",
    "console = Console()\n",
    "\n",
    "md = Markdown(result.data.text_response)\n",
    "console.print(md)\n",
    "\n",
    "rprint(result.data.tools_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReasoningModelQuery(BaseModel):\n",
    "    instruction: str = Field(description=\"The instruction you want give the reasoning model.\")\n",
    "    motivation: str = Field(description=\"The main reason why you ask the reasoning model.\")\n",
    "    additional_context: str = Field(description=\"Add the full context here (e.g., crawled website/markdown text).\")\n",
    "\n",
    "def ask_reasoning_agent(query: ReasoningModelQuery) -> dict:\n",
    "    \"\"\"\n",
    "    Ask a reasoning agent to help you solve problems.\n",
    "\n",
    "    Args:\n",
    "        user_input (ReasoningModelQuery): Contains information about the motivation for the request, an instruction to follow and the additional context (e.g., document, article, PDF, crawled website etc.) \n",
    "\n",
    "    Returns:\n",
    "        dict: The answer of the AI model as a string. Containing the reasoning thoughts and the final response.\n",
    "    \"\"\"\n",
    "\n",
    "    str_query = f\"\"\"\n",
    "    You are working together with other LLM-based agents to answer user questions.\n",
    "    Agents will ask you questions to help them making decisions.\n",
    "    You are a reasoning model and know how to resolve problems.\n",
    "    Take your time thinking about the query of the agent.\n",
    "\n",
    "    Motivation of the agent:\n",
    "    {query.motivation}\n",
    "\n",
    "    Agent Instruction:\n",
    "    {query.instruction}\n",
    "\n",
    "    Additional Context:\n",
    "    {query.additional_context}\n",
    "\n",
    "    \"\"\"\n",
    "    return deepseek_R1_call(str_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenQuestion(BaseModel):\n",
    "    question_number: int = Field(description=\"The question number. Each number has a unique number starting from zero.\", ge=0)\n",
    "    question: str = Field(description=\"A question that needs to be answered\")\n",
    "    notes: list[str] = Field(description=\"A list of notes/information related to the question that help to answer the question as good as possible.\")\n",
    "    rating: int = Field(description=\"The quality of the temporary response (0 to 10)\", ge=0, le=10)\n",
    "\n",
    "class QuestionQueue(BaseModel):\n",
    "    list_of_questions: list[OpenQuestion] = Field(description=\"A list of questions that need to be answered\")\n",
    "\n",
    "question_queue = QuestionQueue(queue=[])\n",
    "\n",
    "def get_open_questions() -> QuestionQueue:\n",
    "    \"\"\"\n",
    "    Returns the current question queue.\n",
    "    \n",
    "    The question queue contains a list of OpenQuestion objects that need to be answered.\n",
    "    Each OpenQuestion object contains a question string, a list of notes that may help to answer the question and a rating.\n",
    "    The rating is the quality of the temporary response (0 to 10) to the question.\n",
    "    \n",
    "    The question queue is a shared object between all agents and is used to keep track of the progress of the question answering process.\n",
    "    \"\"\"\n",
    "    global question_queue\n",
    "\n",
    "    try: \n",
    "        # Make sure that each question has correct unique question number\n",
    "        for k in range(len(question_queue.list_of_questions)):\n",
    "            question_queue.list_of_questions[k].question_number = k\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return question_queue\n",
    "\n",
    "class UpdateRequestQueue(BaseModel):\n",
    "    question_number: int = Field(description=\"The question number. Each number has a unique number starting from zero.\", ge=0)\n",
    "    notes: list[str] = Field(description=\"A list of notes/information related to the question that help to answer the question as good as possible.\")\n",
    "    rating: int = Field(description=\"The quality of the temporary response (0 to 10)\", ge=0, le=10)\n",
    "\n",
    "def update_open_question_in_queue(update_request: UpdateRequestQueue):\n",
    "    \n",
    "    global question_queue\n",
    "    question_number = getattr(update_request, 'question_number', None)\n",
    "\n",
    "    if question_number & question_queue:\n",
    "        if (question_number < len(question_queue.list_of_questions)):\n",
    "\n",
    "            if getattr(update_request, 'notes', None)\n",
    "                question_queue.list_of_questions[question_number].notes = update_request.notes\n",
    "            \n",
    "            if getattr(update_request, 'rating', None)\n",
    "                question_queue.list_of_questions[question_number].rating = update_request.rating\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WebSearchAgent import *\n",
    "system_prompt = \"\"\"\n",
    "    You are a web search expert and your goal is to answer a list of user question using external search tools.\n",
    "    You don't have to solve all questions, just try to find the best answer using only the tools available to you.\n",
    "\n",
    "    You belong to a group of experts that try to answer all questions in a question queue. \n",
    "    At the beginning, there might be many questions that are too complex for you to handle.\n",
    "    Collect information usesing the available search tools an save important notes using the save_notes function/tool.\n",
    "    You will then also give a rating on how complete the answer for each question is, so that the next agent knows which questions to answer next.\n",
    "\n",
    "    Our goal is to do deep research. This means, we don't need quick responses. It's okay, if it takes more than 15 min. to answer all questions in the queue. \n",
    "    You can ask the a reasoning agent to give you feedback about what to search/which tools to use etc., just add all information needed to help you. \n",
    "\n",
    "    How to answer the question in the question queue:\n",
    "        - Pick a question that is currently not answered.\n",
    "        - Focus only on the most important question and only one question.\n",
    "        - Don't asker more than one question.\n",
    "        - Don't answer the question directly, even if you think you know the answer.\n",
    "        - Use the search tools (at least one) to help you collect information.\n",
    "        - If the questions seems to be resolved, there is no need to use more search tools.\n",
    "\n",
    "    Information about the search tools:\n",
    "        - Sometimes many tools are available to you, sometimes maybe only one.\n",
    "        - They only provide an overview of search result (except perplexity search, if tool is available).\n",
    "        - The search usually contain web URLs.\n",
    "        - The crawl_website_async tool be used to convert a website or a PDF in markdown format.\n",
    "        - You can use the reason model to help you decide which url should be processed next.\n",
    "        - You should use each search tool max. once (not more) one question.\n",
    "        - The search tools are cheap to use (don't worry using them).\n",
    "    \n",
    "    Inforrmation about the web crawler:\n",
    "        - The tool needs a web url that leads to a website or a PDF document (e.g., ArXiv paper).\n",
    "        - The tool will return a string representing the website or PDF in markdown format.\n",
    "        - Use it to get more information for a give search result.\n",
    "\n",
    "    Information about the reasoning agent:\n",
    "        - This agent is available to you in form as a tool/function call.\n",
    "        - Use this agent to help you make decisions\n",
    "        - The context window of this agent is large (arround 64k).\n",
    "        - Therefore, you can append the crawled markdown text, when asking questions.\n",
    "        - The agent is cheap to use: \n",
    "            $0.14 / million input tokens (cache hit)\n",
    "            $0.55 / million input tokens (cache miss)\n",
    "            $2.19 / million output tokens\n",
    "        - Don't hesitate using this model to help you with everything.\n",
    "        - You can ask the reasoning agent multiple times in a row.\n",
    "        - The reasoning model returns the reasoning thoughts  and the final response to your query.\n",
    "        - Don't dismiss the reasoning thoughts, they can be very useful.\n",
    "    \n",
    "    Information about the question queue:\n",
    "        - Every agent in the loop or chain has access to the question queue (data structure/database).\n",
    "        - You can get all information about the question queue by using the tool 'get_open_questions'.\n",
    "        - You should use this function only once and decide which question to answer next (most relevant question first).\n",
    "\n",
    "    Here is an example how you can process the questions:\n",
    "        - Start by calling the 'get_open_questions' function to get all open questions.\n",
    "        - Selected one question that seems to be most relevant (use reasoning model if you're not sure).\n",
    "        - Based on the nature of the question select the appropriate search tool (can can use multiple in a row) to get an overview.\n",
    "        - After getting an overview of the search results, consult the reasoning agent, which search results seems most promissing to get good results.\n",
    "        - Use the crawl tool function to get a markdown response from the URL link.\n",
    "        - Use the reasoning model again with the additional context to collect notes/information or get a summary of the given context.\n",
    "        - If you have collected all information/notes for a question, update the question queue by calling the function: 'update_open_question_in_queue'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "tools_list = [ask_reasoning_agent, get_open_questions, update_open_question_in_queue, google_general_search, google_scholar_search, papers_with_code_search, crawl_website_async] #perplexity_search,\n",
    "\n",
    "# Create agent with selected tools\n",
    "agent = Agent(\n",
    "    model,\n",
    "    result_type=Response,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tools_list\n",
    ")\n",
    "\n",
    "#result = await agent.run('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[COMPLETE] ● Database backup created at: /home/dev/.crawl4ai/crawl4ai.db.backup_20250128_155027\n",
      "[INIT].... → Starting database migration...\n",
      "[COMPLETE] ● Migration completed. 0 records processed.\n",
      "[FETCH]... ↓ https://brainchip.com/... | Status: True | Time: 2.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/Projects/deepresearchagent/.venv/lib/python3.13/site-packages/bs4/builder/_lxml.py:124: DeprecationWarning: The 'strip_cdata' option of HTMLParser() has never done anything and will eventually be removed.\n",
      "  parser = parser(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPE].. ◆ Processed https://brainchip.com/... | Time: 138ms\n",
      "[COMPLETE] ● https://brainchip.com/... | Status: True | Total: 3.26s\n"
     ]
    }
   ],
   "source": [
    "markdown = await crawl4ai_website_async(\"https://brainchip.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a console instance\n",
    "console = Console()\n",
    "\n",
    "md = Markdown(markdown)\n",
    "console.print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a console instance\n",
    "console = Console()\n",
    "\n",
    "md = Markdown(markdown)\n",
    "console.print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://google.serper.dev/search \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "results = await google_general_search(\"site:brainchip.com training models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.pydantic.dev\"\n",
    "result = await crawl_website(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"result.json\"\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(result, json_file)\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    result = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = \"pydantic_ai_docs/\"\n",
    "if not exists(destination_folder):\n",
    "    makedirs(destination_folder)\n",
    "\n",
    "for k in range(len(result['data'])):\n",
    "    md = result['data'][k]['markdown']\n",
    "    title = result['data'][k]['metadata']['title']\n",
    "    with open(join(destination_folder, f\"{title}.md\"), \"w\") as file:\n",
    "        file.write(md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
